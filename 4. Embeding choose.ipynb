{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "backed-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nile.api.v1 import (\n",
    "    clusters,\n",
    "    aggregators as na\n",
    ")\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pymystem3 import Mystem\n",
    "import pymorphy2\n",
    "\n",
    "sns.set()\n",
    "pd.set_option('display.min_rows', 50)\n",
    "cluster = clusters.Hahn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-affair",
   "metadata": {},
   "source": [
    "## Подготовка текстового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "technological-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '//home/images/dev/spochukaev/hse_diploma/text_classification_with_answers_2'\n",
    "text_class_2 = cluster.read(path).as_dataframe()\n",
    "\n",
    "path = '//home/images/dev/spochukaev/hse_diploma/text_classification_all_honeypots_3'\n",
    "text_all_2 = cluster.read(path).as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ecological-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_class_2['aggr_answer'] = text_class_2['aggr_answer'].str.decode('utf8')\n",
    "text_class_2['assessors_answer'] = text_class_2['assessors_answer'].str.decode('utf8')\n",
    "text_class_2['some_answer'] = text_class_2['some_answer'].str.decode('utf8')\n",
    "text_class_2['query'] = text_class_2['query'].str.decode('utf8')\n",
    "text_class_2['least_common'] = text_class_2['least_common'].str.decode('utf8')\n",
    "\n",
    "text_all_2['assessors_answer'] = text_all_2['assessors_answer'].str.decode('utf8')\n",
    "text_all_2['query'] = text_all_2['query'].str.decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "equal-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_class_2 = text_class_2.drop_duplicates(subset=['query']).drop('list_answers', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "foster-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_class_2.to_csv('text_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-transition",
   "metadata": {},
   "source": [
    "# Добавление фильтра по языкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "considerable-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_class_2['english'] = text_class_2['query'].apply(lambda x: re.search('[a-zA-Z]', x) != None)\n",
    "text_class_2['russian'] = text_class_2['query'].apply(lambda x: re.search('[А-Яа-я]', x) != None)\n",
    "text_class_2['ukrain'] = text_class_2['query'].apply(lambda x: re.search('[ЇїІіЄєҐґ]', x) != None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unlike-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = text_class_2[(~text_class_2['english']) & (text_class_2['russian']) & (~text_class_2['ukrain'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "acute-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "convert_dict = {\n",
    "    'A':       'ADJ',                                                                                                                                                                                                                                                                    \n",
    "    'ADV':    'ADV',                                                                                                                                                                                                                                                                    \n",
    "    'ADVPRO':  'ADV',                                                                                                                                                                                                                                                                    \n",
    "    'ANUM':    'ADJ',                                                                                                                                                                                                                                                                    \n",
    "    'APRO':    'DET',                                                                                                                                                                                                                                                                    \n",
    "    'COM':     'ADJ',                                                                                                                                                                                                                                                                   \n",
    "    'CONJ':    'SCONJ',                                                                                                                                                                                                                                                                  \n",
    "    'INTJ':    'INTJ',                                                                                                                                                                                                                                                                   \n",
    "    'NONLEX':  'X',                                                                                                                                                                                                                                                                     \n",
    "    'NUM':     'NUM',                                                                                                                                                                                                                                                                    \n",
    "    'PART':    'PART',                                                                                                                                                                                                                                                                   \n",
    "    'PR':      'ADP',                                                                                                                                                                                                                                                                   \n",
    "    'S':       'NOUN',                                                                                                                                                                                                                                                                   \n",
    "    'SPRO':    'PRON',                                                                                                                                                                                                                                                                   \n",
    "    'UNKN':    'X',                                                                                                                                                                                                                                                                     \n",
    "    'V':     'VERB'  \n",
    "}\n",
    "\n",
    "pymorphy2_dict = {\n",
    "    'NOUN': 'NOUN', \n",
    "    'ADJF': 'ADJ', \n",
    "    'ADJS': 'ADJ',\n",
    "    'COMP':     'ADJ', \n",
    "    'VERB':     'VERB',\n",
    "    'INFN':     'VERB', \n",
    "    'PRTF':    'ADV',                                                                                                                                                                                                                                                                    \n",
    "    'PRTS':  'ADV',\n",
    "    'GRND':  'ADV',\n",
    "    'NUMR':     'NUM',                                                                                                                                                                                                                                                                    \n",
    "    'NPRO':    'PRON',                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
    "    'CONJ':    'CONJ',                                                                                                                                                                                                                                                                  \n",
    "    'INTJ':    'INTJ',                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
    "    'PRCL':    'PART',  \n",
    "    'PREP':      'ADP',                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "    'SPRO':    'PRON',\n",
    "    'ADVB': 'ADV',\n",
    "    'PRED': 'ADV'\n",
    " \n",
    "}\n",
    "\n",
    "\n",
    "def tag(word, with_tags=False):\n",
    "    processed = m.parse(word)\n",
    "    if with_tags:\n",
    "        try:\n",
    "            lemma = processed[0].normal_form + \"_\" + pymorphy2_dict[processed[0].tag.POS]\n",
    "        except KeyError:\n",
    "            print(processed[0])\n",
    "            lemma = processed[0].normal_form + \"_X\"\n",
    "    else:\n",
    "        lemma = processed[0].normal_form \n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "technical-copyright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'правильно_ADV'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag('правильно', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "completed-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "for query in df['query']:\n",
    "    query_ = query.lower()\n",
    "    query_ = re.sub(r'[^\\w\\s]',' ',query_)\n",
    "    query_ = re.sub(r'\\d+','',query_)\n",
    "    query_ = re.sub(r'\\s+',' ',query_)\n",
    "    query_ = query_.strip()\n",
    "    updated_query = []\n",
    "    #print(query_)\n",
    "    for word in query_.split(' '):\n",
    "        try:\n",
    "            if len(word) > 3:\n",
    "                word = tag(word)\n",
    "                if word not in stopwords.words(\"russian\"):\n",
    "                    updated_query.append(word)\n",
    "        except KeyError:\n",
    "            print(f'KeyError: query: {query} . Word: {word}')\n",
    "        except IndexError:\n",
    "            print(f'IndexError: query: {query} . Word: {word}')\n",
    "    queries.append({'Initial_query': query, 'Updated_query': ' '.join(updated_query)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-depression",
   "metadata": {},
   "source": [
    "## Пробую navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "disabled-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "exterior-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "\n",
    "path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "navec = Navec.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "alert-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_words = set()\n",
    "unknown_words = set()\n",
    "for query in queries:\n",
    "    for word in query['Updated_query'].split(' '):\n",
    "        if word not in navec:\n",
    "            unknown_words.add(word)\n",
    "        else:\n",
    "            known_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "induced-zambia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8681\n",
      "3628\n"
     ]
    }
   ],
   "source": [
    "print(len(known_words))\n",
    "print(len(unknown_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "reliable-solid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'ацикловира',\n",
       " 'лудшея',\n",
       " 'руский',\n",
       " 'семый',\n",
       " 'честейн',\n",
       " 'микробиолгия',\n",
       " 'мауголь',\n",
       " 'панеттьерь',\n",
       " 'белагропромбанк',\n",
       " 'еврохоккей',\n",
       " 'серябкина',\n",
       " 'ивацевичи',\n",
       " 'брсма',\n",
       " 'лепбук',\n",
       " 'варикоцель',\n",
       " 'требуються',\n",
       " 'таймлёсс',\n",
       " 'оченний',\n",
       " 'сэкс',\n",
       " 'суиня',\n",
       " 'страстнуть',\n",
       " 'фурри',\n",
       " 'трихополый',\n",
       " 'диацент',\n",
       " 'юриевич',\n",
       " 'варюшка',\n",
       " 'райхон',\n",
       " 'фаннинга',\n",
       " 'взломаный',\n",
       " 'шостка',\n",
       " 'минеткать',\n",
       " 'платёж',\n",
       " 'делюкс',\n",
       " 'пропановый',\n",
       " 'варкравт',\n",
       " 'аденокарцинома',\n",
       " 'нүдистый',\n",
       " 'ситилинк',\n",
       " 'киевстарый',\n",
       " 'лораса',\n",
       " 'сивацкай',\n",
       " 'желировать',\n",
       " 'кражный',\n",
       " 'хитман',\n",
       " 'фуджифильм',\n",
       " 'вальгусный',\n",
       " 'дигла',\n",
       " 'сантехнический',\n",
       " 'валюш',\n",
       " 'хавортий',\n",
       " 'хамедорей',\n",
       " 'аркхэма',\n",
       " 'ферритина',\n",
       " 'хемсворт',\n",
       " 'майнкрафт',\n",
       " 'джекман',\n",
       " 'екфт',\n",
       " 'кизларь',\n",
       " 'скелетрон',\n",
       " 'калкина',\n",
       " 'фейсситтинг',\n",
       " 'сузук',\n",
       " 'акулиничев',\n",
       " 'чиназ',\n",
       " 'курцхаар',\n",
       " 'эйджиро',\n",
       " 'скапюшон',\n",
       " 'расклёшить',\n",
       " 'флешерс',\n",
       " 'лачетти',\n",
       " 'оригон',\n",
       " 'сиил',\n",
       " 'страпон',\n",
       " 'мотоскутер',\n",
       " 'кенис',\n",
       " 'арцруни',\n",
       " 'талула',\n",
       " 'народженний',\n",
       " 'гульпери',\n",
       " 'препинание',\n",
       " 'жодино',\n",
       " 'астартёс',\n",
       " 'эсиакад',\n",
       " 'армроса',\n",
       " 'агутиный',\n",
       " 'летьный',\n",
       " 'садяц',\n",
       " 'леново',\n",
       " 'гельминт',\n",
       " 'горынович',\n",
       " 'дорампа',\n",
       " 'леггинс',\n",
       " 'бепантен',\n",
       " 'подкапов',\n",
       " 'катушечный',\n",
       " 'мейкап',\n",
       " 'хинака',\n",
       " 'мелань',\n",
       " 'чурчхела']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unknown_words)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-cholesterol",
   "metadata": {},
   "source": [
    "# Скачка векторов CBOW c RUvectors из Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bacterial-verse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/spochukaev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data \n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "white-tactics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-20 19:40:14--  http://vectors.nlpl.eu/repository/20/220.zip\n",
      "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 64:ff9b::81f0:bdb5\n",
      "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|64:ff9b::81f0:bdb5|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 638171816 (609M) [application/zip]\n",
      "Saving to: ‘220.zip’\n",
      "\n",
      "220.zip             100%[===================>] 608.61M  70.9MB/s    in 8.8s    \n",
      "\n",
      "2021-12-20 19:40:23 (68.8 MB/s) - ‘220.zip’ saved [638171816/638171816]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://vectors.nlpl.eu/repository/20/220.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "integrated-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model.bin'\n",
    "\n",
    "model_ru = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "extensive-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='нексо', tag=OpencorporaTag('UNKN'), normal_form='нексо', score=1.0, methods_stack=((UnknAnalyzer(), 'ксо'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='автоцон', tag=OpencorporaTag('UNKN'), normal_form='автоцон', score=1.0, methods_stack=((UnknAnalyzer(), 'цон'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'авто')))\n",
      "Parse(word='ревва', tag=OpencorporaTag('UNKN'), normal_form='ревва', score=1.0, methods_stack=((UnknAnalyzer(), 'вва'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='ревва', tag=OpencorporaTag('UNKN'), normal_form='ревва', score=1.0, methods_stack=((UnknAnalyzer(), 'вва'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='некст', tag=OpencorporaTag('UNKN'), normal_form='некст', score=1.0, methods_stack=((UnknAnalyzer(), 'кст'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='рейнз', tag=OpencorporaTag('UNKN'), normal_form='рейнз', score=1.0, methods_stack=((UnknAnalyzer(), 'йнз'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='рейши', tag=OpencorporaTag('UNKN'), normal_form='рейши', score=1.0, methods_stack=((UnknAnalyzer(), 'йши'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='деман', tag=OpencorporaTag('UNKN'), normal_form='деман', score=1.0, methods_stack=((UnknAnalyzer(), 'ман'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='денги', tag=OpencorporaTag('UNKN'), normal_form='денги', score=1.0, methods_stack=((UnknAnalyzer(), 'нги'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='дента', tag=OpencorporaTag('UNKN'), normal_form='дента', score=1.0, methods_stack=((UnknAnalyzer(), 'нта'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='дефлю', tag=OpencorporaTag('UNKN'), normal_form='дефлю', score=1.0, methods_stack=((UnknAnalyzer(), 'флю'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='добби', tag=OpencorporaTag('UNKN'), normal_form='добби', score=1.0, methods_stack=((UnknAnalyzer(), 'бби'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'до')))\n",
      "Parse(word='делла', tag=OpencorporaTag('UNKN'), normal_form='делла', score=1.0, methods_stack=((UnknAnalyzer(), 'лла'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='негри', tag=OpencorporaTag('UNKN'), normal_form='негри', score=1.0, methods_stack=((UnknAnalyzer(), 'гри'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='нееет', tag=OpencorporaTag('UNKN'), normal_form='нееет', score=1.0, methods_stack=((UnknAnalyzer(), 'еет'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='некси', tag=OpencorporaTag('UNKN'), normal_form='некси', score=1.0, methods_stack=((UnknAnalyzer(), 'кси'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='пандаг', tag=OpencorporaTag('UNKN'), normal_form='пандаг', score=1.0, methods_stack=((UnknAnalyzer(), 'даг'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'пан')))\n",
      "Parse(word='малодые', tag=OpencorporaTag('UNKN'), normal_form='малодые', score=1.0, methods_stack=((UnknAnalyzer(), 'дые'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'мало')))\n",
      "Parse(word='порножмж', tag=OpencorporaTag('UNKN'), normal_form='порножмж', score=1.0, methods_stack=((UnknAnalyzer(), 'жмж'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'порно')))\n",
      "Parse(word='порнозоо', tag=OpencorporaTag('UNKN'), normal_form='порнозоо', score=1.0, methods_stack=((UnknAnalyzer(), 'зоо'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'порно')))\n",
      "Parse(word='пранки', tag=OpencorporaTag('UNKN'), normal_form='пранки', score=1.0, methods_stack=((UnknAnalyzer(), 'нки'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'пра')))\n",
      "Parse(word='рендж', tag=OpencorporaTag('UNKN'), normal_form='рендж', score=1.0, methods_stack=((UnknAnalyzer(), 'ндж'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='дебби', tag=OpencorporaTag('UNKN'), normal_form='дебби', score=1.0, methods_stack=((UnknAnalyzer(), 'бби'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='интерика', tag=OpencorporaTag('UNKN'), normal_form='интерика', score=1.0, methods_stack=((UnknAnalyzer(), 'ика'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'интер')))\n",
      "Parse(word='дорфф', tag=OpencorporaTag('UNKN'), normal_form='дорфф', score=1.0, methods_stack=((UnknAnalyzer(), 'рфф'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'до')))\n",
      "Parse(word='некст', tag=OpencorporaTag('UNKN'), normal_form='некст', score=1.0, methods_stack=((UnknAnalyzer(), 'кст'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='архивач', tag=OpencorporaTag('UNKN'), normal_form='архивач', score=1.0, methods_stack=((UnknAnalyzer(), 'вач'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'архи')))\n"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "for query in df['query']:\n",
    "    query_ = query.lower()\n",
    "    query_ = re.sub(r'[^\\w\\s]',' ',query_)\n",
    "    query_ = re.sub(r'\\d+','',query_)\n",
    "    query_ = re.sub(r'\\s+',' ',query_)\n",
    "    query_ = query_.strip()\n",
    "    updated_query = []\n",
    "    #print(query_)\n",
    "    for word in query_.split(' '):\n",
    "        try:\n",
    "            if len(word) > 3:\n",
    "                word = tag(word, True)\n",
    "                if word not in stopwords.words(\"russian\"):\n",
    "                    updated_query.append(word)\n",
    "        except KeyError:\n",
    "            print(f'KeyError: query: {query} . Word: {word}')\n",
    "        except IndexError:\n",
    "            print(f'IndexError: query: {query} . Word: {word}')\n",
    "    queries.append({'Initial_query': query, 'Updated_query': ' '.join(updated_query)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "pressing-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_words = set()\n",
    "unknown_words = set()\n",
    "for query in queries:\n",
    "    for word in query['Updated_query'].split(' '):\n",
    "        if word not in model_ru:\n",
    "            unknown_words.add(word)\n",
    "        else:\n",
    "            known_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fantastic-botswana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7342\n",
      "5050\n"
     ]
    }
   ],
   "source": [
    "print(len(known_words))\n",
    "print(len(unknown_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "allied-muscle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'варкравт_NOUN' in model_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "broadband-panama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='шлёпанец', tag=OpencorporaTag('NOUN,inan,masc sing,nomn'), normal_form='шлёпанец', score=0.5, methods_stack=((DictionaryAnalyzer(), 'шлёпанец', 118, 0),)),\n",
       " Parse(word='шлёпанец', tag=OpencorporaTag('NOUN,inan,masc sing,accs'), normal_form='шлёпанец', score=0.5, methods_stack=((DictionaryAnalyzer(), 'шлёпанец', 118, 3),))]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.parse('шлепанец')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "trained-vision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'гербалайф_NOUN',\n",
       " 'жилкин_NOUN',\n",
       " 'кушадас_NOUN',\n",
       " 'пинч_NOUN',\n",
       " 'кролин_NOUN',\n",
       " 'повера_NOUN',\n",
       " 'бежать_ADV',\n",
       " 'нднс_NOUN',\n",
       " 'кидман_NOUN',\n",
       " 'динагуля_NOUN',\n",
       " 'мясникович_NOUN',\n",
       " 'меренговый_ADJ',\n",
       " 'кузьменко_NOUN',\n",
       " 'редми_X',\n",
       " 'шплинт_NOUN',\n",
       " 'санинск_NOUN',\n",
       " 'европрестиж_NOUN',\n",
       " 'полмимерный_ADJ',\n",
       " 'гирич_NOUN',\n",
       " 'ариаморган_NOUN',\n",
       " 'запрешить_ADV',\n",
       " 'клёш_NOUN',\n",
       " 'булутс_NOUN',\n",
       " 'окк_NOUN',\n",
       " 'ривольвера_NOUN',\n",
       " 'фесить_ADV',\n",
       " 'авив_NOUN',\n",
       " 'аревик_NOUN',\n",
       " 'нейромультивит_NOUN',\n",
       " 'вацап_NOUN',\n",
       " 'духтари_NOUN',\n",
       " 'шпиц_NOUN',\n",
       " 'симб_NOUN',\n",
       " 'шлёпанец_NOUN',\n",
       " 'опарыш_NOUN',\n",
       " 'павлов_NOUN',\n",
       " 'сквирт_NOUN',\n",
       " 'джонатан_NOUN',\n",
       " 'ланцберг_NOUN',\n",
       " 'кросться_VERB',\n",
       " 'берджесс_NOUN',\n",
       " 'расдвегать_VERB',\n",
       " 'киевстарый_ADJ',\n",
       " 'маркес_NOUN',\n",
       " 'кабзиятгакарша_NOUN',\n",
       " 'термобельё_NOUN',\n",
       " 'юнайтед_NOUN',\n",
       " 'монклер_NOUN',\n",
       " 'буллка_NOUN',\n",
       " 'диснейленд_NOUN',\n",
       " 'скримера_NOUN',\n",
       " 'нарвал_NOUN',\n",
       " 'уайлдёр_NOUN',\n",
       " 'обьгэс_NOUN',\n",
       " 'агелера_NOUN',\n",
       " 'аквапринт_NOUN',\n",
       " 'крошить_ADV',\n",
       " 'платтить_ADV',\n",
       " 'съёмник_NOUN',\n",
       " 'замерщик_NOUN',\n",
       " 'милано_NOUN',\n",
       " 'блуй_NOUN',\n",
       " 'сэксить_VERB',\n",
       " 'сталенхаг_NOUN',\n",
       " 'султанит_NOUN',\n",
       " 'ростверк_NOUN',\n",
       " 'резяпкина_NOUN',\n",
       " 'кудо_NOUN',\n",
       " 'лахта_NOUN',\n",
       " 'боярд_NOUN',\n",
       " 'помодоро_NOUN',\n",
       " 'комрат_NOUN',\n",
       " 'погубившма_NOUN',\n",
       " 'элтон_NOUN',\n",
       " 'степашка_NOUN',\n",
       " 'араго_NOUN',\n",
       " 'секисовка_NOUN',\n",
       " 'верзилов_NOUN',\n",
       " 'таджикистан_NOUN',\n",
       " 'отожоновый_ADJ',\n",
       " 'гурченко_NOUN',\n",
       " 'себеж_NOUN',\n",
       " 'гданьск_NOUN',\n",
       " 'приствка_NOUN',\n",
       " 'чарли_NOUN',\n",
       " 'гасай_NOUN',\n",
       " 'костнер_NOUN',\n",
       " 'хлорофитум_NOUN',\n",
       " 'паховой_ADJ',\n",
       " 'беллуччи_NOUN',\n",
       " 'гарыцвета_NOUN',\n",
       " 'пумба_NOUN',\n",
       " 'шпатлевочный_ADJ',\n",
       " 'анимировать_ADV',\n",
       " 'ухта_NOUN',\n",
       " 'бедный_NOUN',\n",
       " 'толмацкий_ADJ',\n",
       " 'весёлка_NOUN',\n",
       " 'руфина_NOUN']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unknown_words)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-course",
   "metadata": {},
   "source": [
    "# Скачка векторов FASTTEXT c RUvectors из Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "harmful-fiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/spochukaev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data \n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "gorgeous-chamber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-20 20:41:50--  http://vectors.nlpl.eu/repository/20/213.zip\n",
      "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 64:ff9b::81f0:bdb5\n",
      "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|64:ff9b::81f0:bdb5|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1485270300 (1.4G) [application/zip]\n",
      "Saving to: ‘213.zip’\n",
      "\n",
      "213.zip             100%[===================>]   1.38G  71.6MB/s    in 20s     \n",
      "\n",
      "2021-12-20 20:42:10 (71.7 MB/s) - ‘213.zip’ saved [1485270300/1485270300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://vectors.nlpl.eu/repository/20/213.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "metropolitan-corps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  213.zip\n",
      "  inflating: meta.json               \n",
      "  inflating: model.model             \n",
      "  inflating: model.model.vectors_ngrams.npy  \n",
      "  inflating: model.model.vectors.npy  \n",
      "  inflating: model.model.vectors_vocab.npy  \n",
      "  inflating: README                  \n"
     ]
    }
   ],
   "source": [
    "! unzip 213.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "color-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model.model'\n",
    "\n",
    "big_model = gensim.models.fasttext.FastTextKeyedVectors.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "atlantic-hughes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_model['айфон'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "still-advantage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='нексо', tag=OpencorporaTag('UNKN'), normal_form='нексо', score=1.0, methods_stack=((UnknAnalyzer(), 'ксо'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='редми', tag=OpencorporaTag('UNKN'), normal_form='редми', score=1.0, methods_stack=((UnknAnalyzer(), 'дми'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='автоцон', tag=OpencorporaTag('UNKN'), normal_form='автоцон', score=1.0, methods_stack=((UnknAnalyzer(), 'цон'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'авто')))\n",
      "Parse(word='ревва', tag=OpencorporaTag('UNKN'), normal_form='ревва', score=1.0, methods_stack=((UnknAnalyzer(), 'вва'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='ревва', tag=OpencorporaTag('UNKN'), normal_form='ревва', score=1.0, methods_stack=((UnknAnalyzer(), 'вва'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='некст', tag=OpencorporaTag('UNKN'), normal_form='некст', score=1.0, methods_stack=((UnknAnalyzer(), 'кст'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='рейнз', tag=OpencorporaTag('UNKN'), normal_form='рейнз', score=1.0, methods_stack=((UnknAnalyzer(), 'йнз'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='рейши', tag=OpencorporaTag('UNKN'), normal_form='рейши', score=1.0, methods_stack=((UnknAnalyzer(), 'йши'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='деман', tag=OpencorporaTag('UNKN'), normal_form='деман', score=1.0, methods_stack=((UnknAnalyzer(), 'ман'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='денги', tag=OpencorporaTag('UNKN'), normal_form='денги', score=1.0, methods_stack=((UnknAnalyzer(), 'нги'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='дента', tag=OpencorporaTag('UNKN'), normal_form='дента', score=1.0, methods_stack=((UnknAnalyzer(), 'нта'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='дефлю', tag=OpencorporaTag('UNKN'), normal_form='дефлю', score=1.0, methods_stack=((UnknAnalyzer(), 'флю'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='добби', tag=OpencorporaTag('UNKN'), normal_form='добби', score=1.0, methods_stack=((UnknAnalyzer(), 'бби'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'до')))\n",
      "Parse(word='делла', tag=OpencorporaTag('UNKN'), normal_form='делла', score=1.0, methods_stack=((UnknAnalyzer(), 'лла'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='негри', tag=OpencorporaTag('UNKN'), normal_form='негри', score=1.0, methods_stack=((UnknAnalyzer(), 'гри'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='нееет', tag=OpencorporaTag('UNKN'), normal_form='нееет', score=1.0, methods_stack=((UnknAnalyzer(), 'еет'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='некси', tag=OpencorporaTag('UNKN'), normal_form='некси', score=1.0, methods_stack=((UnknAnalyzer(), 'кси'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='пандаг', tag=OpencorporaTag('UNKN'), normal_form='пандаг', score=1.0, methods_stack=((UnknAnalyzer(), 'даг'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'пан')))\n",
      "Parse(word='малодые', tag=OpencorporaTag('UNKN'), normal_form='малодые', score=1.0, methods_stack=((UnknAnalyzer(), 'дые'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'мало')))\n",
      "Parse(word='порножмж', tag=OpencorporaTag('UNKN'), normal_form='порножмж', score=1.0, methods_stack=((UnknAnalyzer(), 'жмж'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'порно')))\n",
      "Parse(word='порнозоо', tag=OpencorporaTag('UNKN'), normal_form='порнозоо', score=1.0, methods_stack=((UnknAnalyzer(), 'зоо'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'порно')))\n",
      "Parse(word='пранки', tag=OpencorporaTag('UNKN'), normal_form='пранки', score=1.0, methods_stack=((UnknAnalyzer(), 'нки'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'пра')))\n",
      "Parse(word='рендж', tag=OpencorporaTag('UNKN'), normal_form='рендж', score=1.0, methods_stack=((UnknAnalyzer(), 'ндж'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'ре')))\n",
      "Parse(word='дебби', tag=OpencorporaTag('UNKN'), normal_form='дебби', score=1.0, methods_stack=((UnknAnalyzer(), 'бби'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'де')))\n",
      "Parse(word='интерика', tag=OpencorporaTag('UNKN'), normal_form='интерика', score=1.0, methods_stack=((UnknAnalyzer(), 'ика'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'интер')))\n",
      "Parse(word='дорфф', tag=OpencorporaTag('UNKN'), normal_form='дорфф', score=1.0, methods_stack=((UnknAnalyzer(), 'рфф'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'до')))\n",
      "Parse(word='некст', tag=OpencorporaTag('UNKN'), normal_form='некст', score=1.0, methods_stack=((UnknAnalyzer(), 'кст'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'не')))\n",
      "Parse(word='архивач', tag=OpencorporaTag('UNKN'), normal_form='архивач', score=1.0, methods_stack=((UnknAnalyzer(), 'вач'), (KnownPrefixAnalyzer(known_prefixes=<...>, min_remainder_length=3, score_multiplier=0.75), 'архи')))\n"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "for query in df['query']:\n",
    "    query_ = query.lower()\n",
    "    query_ = re.sub(r'[^\\w\\s]',' ',query_)\n",
    "    query_ = re.sub(r'\\d+','',query_)\n",
    "    query_ = re.sub(r'\\s+',' ',query_)\n",
    "    query_ = query_.strip()\n",
    "    updated_query = []\n",
    "    #print(query_)\n",
    "    for word in query_.split(' '):\n",
    "        try:\n",
    "            if len(word) > 3:\n",
    "                word = tag(word, True)\n",
    "                if word not in stopwords.words(\"russian\"):\n",
    "                    updated_query.append(word)\n",
    "        except KeyError:\n",
    "            print(f'KeyError: query: {query} . Word: {word}')\n",
    "        except IndexError:\n",
    "            print(f'IndexError: query: {query} . Word: {word}')\n",
    "    queries.append({'Initial_query': query, 'Updated_query': ' '.join(updated_query)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "healthy-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_words = set()\n",
    "unknown_words = set()\n",
    "for query in queries:\n",
    "    for word in query['Updated_query'].split(' '):\n",
    "        if word not in big_model:\n",
    "            unknown_words.add(word)\n",
    "        else:\n",
    "            known_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "sixth-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12392\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(known_words))\n",
    "print(len(unknown_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-cable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
